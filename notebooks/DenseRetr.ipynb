{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ijson\n",
        "import ijson\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import gc\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "INPUT_FILE = '/content/drive/MyDrive/BM25 Files/hover_dev_bm25_top100.json'\n",
        "MODEL_NAME = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
        "BATCH_SIZE = 16\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ============================================================================\n",
        "# Initialize Model First\n",
        "# ============================================================================\n",
        "print(f\"Loading model: {MODEL_NAME}\")\n",
        "model = SentenceTransformer(MODEL_NAME, device=DEVICE)\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Count claims using streaming (no full load)\n",
        "# ============================================================================\n",
        "print(\"\\nCounting claims...\")\n",
        "claim_count = 0\n",
        "with open(INPUT_FILE, 'rb') as f:\n",
        "    parser = ijson.kvitems(f, '')\n",
        "    for _ in parser:\n",
        "        claim_count += 1\n",
        "\n",
        "print(f\"Total claims: {claim_count}\")\n",
        "print(\"Memory safe - never loaded full file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QN5o0cKmVM-9",
        "outputId": "0ce72304-5737-4d19-ab25-7e85b62146d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ijson\n",
            "  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.4.0.post0\n",
            "Loading model: sentence-transformers/multi-qa-mpnet-base-dot-v1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Counting claims...\n",
            "Total claims: 4000\n",
            "Memory safe - never loaded full file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug: check structure\n",
        "with open(INPUT_FILE, 'rb') as f:\n",
        "    parser = ijson.kvitems(f, '')\n",
        "    claim_id, claim_data = next(parser)\n",
        "    print(\"Claim keys:\", claim_data.keys())\n",
        "    print(\"First doc keys:\", claim_data['retrieved_docs'][0].keys())\n",
        "    print(\"First doc sample:\", claim_data['retrieved_docs'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fcWo7h9mZJBy",
        "outputId": "b076ee36-e02f-4f9c-f0ea-8a5fc07a3a21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claim keys: dict_keys(['claim', 'retrieved_docs', 'label', 'supporting_facts'])\n",
            "First doc keys: dict_keys(['doc_id', 'title', 'sentences', 'score', 'url'])\n",
            "First doc sample: {'doc_id': '1459568', 'title': 'Don Was', 'sentences': ['Don Was', 'Don Edward Fagenson (born September 13, 1952), known as Don Was, is an American <a href=\"musician\">musician</a>, <a href=\"record%20producer\">record producer</a> and <a href=\"record%20executive\">record executive</a>.', ' Primarily a <a href=\"Bass%20guitar\">bass</a> player, Was led the 1980s funk rock band <a href=\"Was%20%28Not%20Was%29\">Was (Not Was)</a>.', ' In later years he produced songs and albums for a large number of popular recording artists.', ' In 2012, he became president of jazz music label <a href=\"Blue%20Note%20Records\">Blue Note Records</a>.', 'Born in <a href=\"Detroit%2C%20Michigan\">Detroit, Michigan</a>, Was graduated from <a href=\"Oak%20Park%20High%20School%20%28Michigan%29\">Oak Park High School</a> in the Detroit suburb of Oak Park, then attended the <a href=\"University%20of%20Michigan\">University of Michigan</a> at <a href=\"Ann%20Arbor%2C%20Michigan\">Ann Arbor</a> but dropped out after the first year.', ' A <a href=\"journeyman\">journeyman</a> musician, he grew up listening to the <a href=\"Detroit%20blues\">Detroit blues</a> sound and the <a href=\"jazz\">jazz</a> music of <a href=\"John%20Coltrane\">John Coltrane</a> and <a href=\"Miles%20Davis\">Miles Davis</a>.', 'Using the stage name \"Don Was\", he formed the group <a href=\"Was%20%28Not%20Was%29\">Was (Not Was)</a> with school friend David Weiss (<a href=\"David%20Was\">David Was</a>).', ' The group found commercial success in the 1980s – releasing four albums and logging several hit records.', ' A jazz/R&B album of <a href=\"Hank%20Williams\">Hank Williams</a> covers, \"<a href=\"Forever%27s%20A%20Long%2C%20Long%20Time\">Forever\\'s A Long, Long Time</a>\" was released in 1997, under the name Orquestra Was.', ' In 2008, Was (Not Was) reunited for an acclaimed new album and tour.', 'Was has received three Grammy Awards including the 1994 <a href=\"Grammy%20Award%20for%20Producer%20of%20the%20Year%2C%20Non-Classical\">Grammy Award for Producer of the Year</a>.', ' He produced several albums for <a href=\"Bonnie%20Raitt\">Bonnie Raitt</a> including her \"<a href=\"Nick%20of%20Time%20%28album%29\">Nick of Time</a>\" album that won the 1989 <a href=\"Grammy%20Award%20for%20Album%20of%20the%20Year\">Grammy Award for Album of the Year</a>.', ' Don also collaborated with co-producer <a href=\"Ziggy%20Marley\">Ziggy Marley</a>, on \"Family Time\", winner of 2009\\'s Best Musical Album For Children.', 'He served as music director and/or consultant for several motion pictures such as \"<a href=\"Thelma%20and%20Louise\">Thelma and Louise</a>\", \"<a href=\"The%20Rainmaker%20%281997%20film%29\">The Rainmaker</a>\", \"<a href=\"Hope%20Floats\">Hope Floats</a>\", \"<a href=\"Phenomenon%20%28film%29\">Phenomenon</a>\", \"<a href=\"Tin%20Cup\">Tin Cup</a>\", \"<a href=\"Honeymoon%20in%20Vegas\">Honeymoon in Vegas</a>\", \"<a href=\"8%20Seconds\">8 Seconds</a>\", \"<a href=\"Switch\">Switch</a>\", \"<a href=\"The%20Freshman%20%281990%20film%29\">The Freshman</a>\", \"<a href=\"Days%20of%20Thunder\">Days of Thunder</a>\", \"<a href=\"Michael%20%281996%20film%29\">Michael</a>\", \"<a href=\"Pr%C3%AAt-%C3%A0-Porter%20%28film%29\">Prêt-à-Porter</a>\", \"<a href=\"Boys%20on%20the%20Side\">Boys on the Side</a>\", \"<a href=\"Toy%20Story\">Toy Story</a>\" and \"<a href=\"The%20Paper%20%28film%29\">The Paper</a>\".', 'In 1997, he directed and produced a documentary, \"<a href=\"I%20Just%20Wasn%27t%20Made%20for%20These%20Times\">I Just Wasn\\'t Made for These Times</a>\", about former Beach Boy <a href=\"Brian%20Wilson\">Brian Wilson</a>.', ' The film debuted at the <a href=\"Sundance%20Film%20Festival\">Sundance Film Festival</a> and won the San Francisco Film Festival\\'s Golden Gate Award.', ' He also received the British Academy Award (<a href=\"BAFTA\">BAFTA</a>) for Best Original Score in recognition of his compositions for the film \"<a href=\"Backbeat%20%28film%29\">Backbeat</a>\".', 'Was, who is a fan of <a href=\"the%20Rolling%20Stones\">the Rolling Stones</a> and saw them in concert when he was age 12 in 1964, produced their albums \"Voodoo Lounge\", \"Stripped\", \"Bridges to Babylon\", \"Forty Licks\", \"Live Licks\", \"A Bigger Bang\" and \"Blue & Lonesome\".', ' He also worked on the <a href=\"Rolling%20Stones\">Rolling Stones</a>\\'s reissues \"<a href=\"Exile%20on%20Main%20Street\">Exile on Main Street</a>\", released in May 2010 and \"<a href=\"Some%20Girls\">Some Girls</a>\" released in October 2011.', ' Was scoured old master recordings of the albums for lost gems, remastering some songs while producing entirely new vocals and tracks on others.', 'Since 2008, Was has hosted the proceedings (and led the house band) at the \"Detroit All-Star Revue\", an annual showcase of local acts from the <a href=\"Detroit%20music\">Detroit music scene</a>.', 'From 2009 to 2012, Don hosted a weekly radio show on Sirius XM satellite radio\\'s <a href=\"Outlaw%20Country%20%28Sirius%20XM%29\">Outlaw Country</a> channel called \"The Motor City Hayride\".', ' During the 2011 season of American Idol, Was appeared in several episodes producing contestants Haley Reinhart, Scotty McCreery, Paul McDonald, Lauren Alaina and Casey Abrams.', 'In January 2012, he was appointed president of the jazz record label, <a href=\"Blue%20Note%20Records\">Blue Note Records</a> in succession to <a href=\"Bruce%20Lundvall\">Bruce Lundvall</a>.', 'He won the 2014 Emmy Award for Outstanding Music Direction for his work on the CBS TV special \"The Beatles: The Night That Changed America.\"', 'On November 18, 2015, at <a href=\"DAR%20Constitution%20Hall\">DAR Constitution Hall</a> in Washington DC, he led the house band that performed at a concert celebrating <a href=\"Willie%20Nelson\">Willie Nelson</a>, recipient of the 2015 <a href=\"Library%20of%20Congress\">Library of Congress</a> <a href=\"Gershwin%20Prize%20for%20Popular%20Song\">Gershwin Prize for Popular Song</a>.', 'Don Was is the father of <a href=\"Eve%206\">Eve 6</a> drummer <a href=\"Tony%20Fagenson\">Tony Fagenson</a> and also Henry and Solomon Fagenson.', ' He is married to former Virgin Records A&R executive and video director Gemma Corfield.', ' He is the brother of public official Dr. Nancy Fagenson Potok, former Principal Associate Director and chief financial officer of the US Census Bureau and currently Deputy Undersecretary for Economic Affairs at the US Department of Commerce.'], 'score': Decimal('115.60873'), 'url': 'https://en.wikipedia.org/wiki?curid=1459568'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import json\n",
        "from decimal import Decimal\n",
        "\n",
        "# ============================================================================\n",
        "# Re-ranking Function\n",
        "# ============================================================================\n",
        "def rerank_documents(claim_text, documents, model, batch_size=16):\n",
        "    \"\"\"Re-rank documents using dense retrieval.\"\"\"\n",
        "    # Encode claim\n",
        "    claim_embedding = model.encode(claim_text, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "    # Extract document texts (join sentences)\n",
        "    doc_texts = [' '.join(doc['sentences']) for doc in documents]\n",
        "\n",
        "    # Batch encode documents\n",
        "    doc_embeddings = model.encode(\n",
        "        doc_texts,\n",
        "        batch_size=batch_size,\n",
        "        convert_to_tensor=True,\n",
        "        show_progress_bar=False\n",
        "    )\n",
        "\n",
        "    # Compute similarity scores (dot product)\n",
        "    scores = torch.matmul(doc_embeddings, claim_embedding)\n",
        "    scores = scores.cpu().numpy()\n",
        "\n",
        "    # Add dense scores to documents\n",
        "    for i, doc in enumerate(documents):\n",
        "        doc['dense_score'] = float(scores[i])\n",
        "        doc['bm25_score'] = float(doc['score'])  # Convert Decimal to float\n",
        "\n",
        "    # Sort by dense score (descending)\n",
        "    reranked_docs = sorted(documents, key=lambda x: x['dense_score'], reverse=True)\n",
        "\n",
        "    # Clean up\n",
        "    del claim_embedding, doc_embeddings, scores\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return reranked_docs\n",
        "\n",
        "# ============================================================================\n",
        "# Custom JSON encoder for Decimal\n",
        "# ============================================================================\n",
        "class DecimalEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, Decimal):\n",
        "            return float(obj)\n",
        "        return super(DecimalEncoder, self).default(obj)\n",
        "\n",
        "# ============================================================================\n",
        "# Process with Streaming (Resume from checkpoint)\n",
        "# ============================================================================\n",
        "OUTPUT_FILE = '/content/drive/MyDrive/BM25 Files/hover_dev_dense_reranked_top100.json'\n",
        "SAVE_EVERY = 50\n",
        "\n",
        "print(\"\\nRe-ranking documents...\")\n",
        "\n",
        "# Load checkpoint if exists\n",
        "try:\n",
        "    with open(OUTPUT_FILE + '.tmp', 'r') as f:\n",
        "        reranked_results = json.load(f)\n",
        "    print(f\"Resuming: Loaded {len(reranked_results)} already processed claims\")\n",
        "except:\n",
        "    reranked_results = {}\n",
        "    print(\"Starting fresh\")\n",
        "\n",
        "processed = len(reranked_results)\n",
        "\n",
        "with open(INPUT_FILE, 'rb') as f:\n",
        "    parser = ijson.kvitems(f, '')\n",
        "\n",
        "    for claim_id, claim_data in tqdm(parser, total=claim_count, desc=\"Processing\"):\n",
        "        # Skip already processed\n",
        "        if claim_id in reranked_results:\n",
        "            continue\n",
        "\n",
        "        claim_text = claim_data['claim']\n",
        "        retrieved_docs = claim_data['retrieved_docs']\n",
        "\n",
        "        # Re-rank\n",
        "        reranked_docs = rerank_documents(claim_text, retrieved_docs, model, BATCH_SIZE)\n",
        "\n",
        "        # Store\n",
        "        reranked_results[claim_id] = {\n",
        "            'claim': claim_text,\n",
        "            'retrieved_docs': reranked_docs\n",
        "        }\n",
        "\n",
        "        processed += 1\n",
        "\n",
        "        # Periodic save\n",
        "        if processed % SAVE_EVERY == 0:\n",
        "            with open(OUTPUT_FILE + '.tmp', 'w') as out:\n",
        "                json.dump(reranked_results, out, cls=DecimalEncoder)\n",
        "            gc.collect()\n",
        "\n",
        "# Final save\n",
        "print(f\"\\nSaving to {OUTPUT_FILE}\")\n",
        "with open(OUTPUT_FILE, 'w') as f:\n",
        "    json.dump(reranked_results, f, indent=2, cls=DecimalEncoder)\n",
        "\n",
        "print(\"✓ Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F70nu-stVPod",
        "outputId": "659a9289-d314-4975-cdd7-e6bc9aa917b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Re-ranking documents...\n",
            "Starting fresh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 4000/4000 [3:41:23<00:00,  3.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving to /content/drive/MyDrive/BM25 Files/hover_dev_dense_reranked_top100.json\n",
            "✓ Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Compute Metrics\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"METRIC EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Build ground truth from BM25 file (it has supporting_facts)\n",
        "print(\"Building ground truth from BM25 results...\")\n",
        "gt_map = {}\n",
        "\n",
        "with open(INPUT_FILE, 'rb') as f:\n",
        "    parser = ijson.kvitems(f, '')\n",
        "    for claim_id, claim_data in parser:\n",
        "        supporting_facts = set()\n",
        "        for fact in claim_data.get('supporting_facts', []):\n",
        "            # Format: [title, sentence_id]\n",
        "            supporting_facts.add(f\"{fact[0]}_{fact[1]}\")\n",
        "        gt_map[claim_id] = supporting_facts\n",
        "\n",
        "print(f\"Loaded ground truth for {len(gt_map)} claims\")\n",
        "\n",
        "# Compute metrics\n",
        "def compute_metrics(results, ground_truth, k=10):\n",
        "    total_retrieved = 0\n",
        "    total_relevant = 0\n",
        "    claims_with_relevant = 0\n",
        "\n",
        "    for claim_id, data in results.items():\n",
        "        if claim_id not in ground_truth:\n",
        "            continue\n",
        "\n",
        "        relevant_docs = ground_truth[claim_id]\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # Build set using title_sentenceID format\n",
        "        top_k_docs = set()\n",
        "        for doc in data['retrieved_docs'][:k]:\n",
        "            title = doc['title']\n",
        "            # Add all sentences from this doc\n",
        "            for sent_id in range(len(doc['sentences'])):\n",
        "                top_k_docs.add(f\"{title}_{sent_id}\")\n",
        "\n",
        "        retrieved_relevant = top_k_docs & relevant_docs\n",
        "\n",
        "        total_retrieved += len(retrieved_relevant)\n",
        "        total_relevant += len(relevant_docs)\n",
        "\n",
        "        if len(retrieved_relevant) > 0:\n",
        "            claims_with_relevant += 1\n",
        "\n",
        "    recall = total_retrieved / total_relevant if total_relevant > 0 else 0\n",
        "    coverage = claims_with_relevant / len(results) if len(results) > 0 else 0\n",
        "\n",
        "    return recall, coverage\n",
        "\n",
        "# Re-run metrics\n",
        "print(\"\\nBM25 (Original) Metrics:\")\n",
        "bm25_recall, bm25_coverage = compute_metrics(bm25_results, gt_map, k=10)\n",
        "print(f\"  Recall@10:   {bm25_recall*100:.2f}%\")\n",
        "print(f\"  Coverage@10: {bm25_coverage*100:.2f}%\")\n",
        "\n",
        "print(\"\\nDense Re-ranking Metrics:\")\n",
        "dense_recall, dense_coverage = compute_metrics(reranked_results, gt_map, k=10)\n",
        "print(f\"  Recall@10:   {dense_recall*100:.2f}%\")\n",
        "print(f\"  Coverage@10: {dense_coverage*100:.2f}%\")\n",
        "\n",
        "print(\"\\nImprovement:\")\n",
        "print(f\"  Recall@10:   {(dense_recall - bm25_recall)*100:+.2f}pp\")\n",
        "print(f\"  Coverage@10: {(dense_coverage - bm25_coverage)*100:+.2f}pp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9qGQQQQaVTL1",
        "outputId": "53fe8708-53aa-4b48-8472-b86adcca4af6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC EVALUATION\n",
            "============================================================\n",
            "Building ground truth from BM25 results...\n",
            "Loaded ground truth for 4000 claims\n",
            "\n",
            "BM25 (Original) Metrics:\n",
            "  Recall@10:   33.76%\n",
            "  Coverage@10: 70.65%\n",
            "\n",
            "Dense Re-ranking Metrics:\n",
            "  Recall@10:   43.24%\n",
            "  Coverage@10: 83.97%\n",
            "\n",
            "Improvement:\n",
            "  Recall@10:   +9.48pp\n",
            "  Coverage@10: +13.32pp\n"
          ]
        }
      ]
    }
  ]
}